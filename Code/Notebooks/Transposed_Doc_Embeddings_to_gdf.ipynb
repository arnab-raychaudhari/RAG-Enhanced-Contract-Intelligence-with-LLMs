{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROGRAM OVERVIEW**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this program is to convert transposed document labels, along with their embeddings, into a .gdf (General Data Format) file. The .gdf file will serve as the input for creating a network analysis document using Gephi software.\n",
    "\n",
    "More details - https://github.com/jphall663/corr_graph/blob/master/csv2gdf.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required **Libraries** and **Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "#import time\n",
    "#from IPython.display import Image # type: ignore\n",
    "#from IPython.display import display # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the features (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements in X_2: 154\n",
      "X_2 (unique values): ['cobank', 'cotton', 'proposals', '–', 'land', 'urban', 'fs', 'reenrollment', 'usda', '-400', 'renewable', 'veterinary', 'programs', 'federal', 'livestock', 'hazard', 'broadband', 'fcic', 'similar', 'duration', 'easement', 'csp', 'specified', 'coverage', 'survey', 'payments', 'labeling', 'provides', 'ce', 'conservation', 'technical', 'title', 'state', 'grants', 'farm', 'saf', 'epa', 'crp', 'oak', 'biobased', 'functions', '”', 'million', 'fifra', 'easements', 'acres', 'billion', 'dairy', 'partnerships', 'requires', 'request', 'cbo', 'would', 'per', 'task', 'u.s.c', 'ohs', 'report', 'projects', 'income', 'microloans', 'forest', 'honey', 'acep', 'property', 'appropriations', 'hemp', 'practices', 'insurance', 'senate', '400', 'institutions', 'base', 'water', 'allows', 'administrative', 'defines', 'species', '•', 'tsp', 'commodities', 'ffp', 'annually', 'rac', 'ventures', 'use', 'sugar', '2024', 'hazardous', 'park', 'payment', 'national', 'rural', 'nfs', 'current', 'ale', 'giant', 'roads', 'biochar', 'reinsurance', 'agencies', 'fy2029', 'school', 'marketing', 'subtitle', 'registration', 'available', 'labor', 'organic', 'milk', 'issues', 'early', 'nrcs', 'dogs', 'research', 'funding', 'crop', 'losses', 'incentive', 'program', 'specialty', 'policy', 'information', '“', 'detention', 'tfp', 'wool', 'county', 'cap', 'food', 'bill', 'rental', '7', 'trade', 'lifetime', 'h.r', 'trust', 'beginning', 'allotments', 'ales', 'cost', 'enrollment', 'loans', 'energy', 'production', 'snap', 'agricultural', 'wood', '................................', 'authorizes', '16', 'operations', 'infrastructure', 'entities']\n"
     ]
    }
   ],
   "source": [
    "# Set the directory path to the location where the .csv file containing the transposed embeddings is located.\n",
    "df = pd.read_csv('/Users/arnabraychaudhari/Documents/6317/Project_LLM_and_RAG_2024_GWU/Farm_Bill_label_with_transposed_embeddings.csv')\n",
    "X_1 = []\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    # Iterate from 1 to 358 (No.of columns in Tranposed Embeddings .csv - 1) and check for prefix in column names\n",
    "    for i in range(1, 358):\n",
    "        prefix = f'DocID_{i}_Label_'\n",
    "        if col.startswith(prefix):\n",
    "            # Remove the prefix and add the remaining part to X_1\n",
    "            X_1.append(col.replace(prefix, ''))\n",
    "            break\n",
    "\n",
    "# Step 3: Remove duplicates to create X_2\n",
    "X_2 = list(set(X_1))\n",
    "num_elements_X_2 = len(X_2)\n",
    "# Display the lists\n",
    "#print(\"X_1 (with possible duplicates):\", X_1)\n",
    "print(f\"Number of unique elements in X_2: {num_elements_X_2}\")\n",
    "print(\"X_2 (unique values):\", X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define user-supplied constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute Pearson correlation threshold\n",
    "# above which a pair of correlated variables is written to the gdf\n",
    "CORR_THRESHOLD = 0.3 \n",
    "\n",
    "# path at which to read input .csv\n",
    "IN_FILE = '/Users/arnabraychaudhari/Documents/6317/Project_LLM_and_RAG_2024_GWU/Farm_Bill_label_with_transposed_embeddings.csv'\n",
    "\n",
    "# path at which to write output .gdf\n",
    "# WARNING: will be over-written!!\n",
    "OUT_FILE = '/Users/arnabraychaudhari/Documents/6317/Project_LLM_and_RAG_2024_GWU/Farm_Bill_train.gdf'\n",
    "\n",
    "# threshold for categorical levels \n",
    "# above which a variable will not be encoded \n",
    "# and written to the gdf\n",
    "NUM_LEVELS_THRESHOLD = 25\n",
    "\n",
    "# input variables (X_2) to be considered \n",
    "# for encoding and writing to gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function for writing gdf from Pearson correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gdf(corr_frame):\n",
    "\n",
    "    \"\"\" Writes a GDF suitable for use with Gephi: https://gephi.org/.\n",
    "    \n",
    "    Args:\n",
    "        corr_frame: Pandas DataFrame of pair-wise Pearson correlations.\n",
    "        \n",
    "    Return: Path of written file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(OUT_FILE, 'w+', encoding='utf-8') as out:\n",
    "\n",
    "        # write node list\n",
    "        out.write('nodedef>name VARCHAR,label VARCHAR\\n')\n",
    "        for i in range(0, corr_frame.shape[0]):\n",
    "            out.write(str(i) + ',' + corr_frame.columns[i] + '\\n')\n",
    "\n",
    "        # write edge list\n",
    "        # edge weight is absolute Pearson correlation\n",
    "        out.write('edgedef>node1 VARCHAR,node2 VARCHAR, weight DOUBLE\\n')\n",
    "        for i in range(0, corr_frame.shape[0]):\n",
    "            for j in range(0, corr_frame.shape[1]):\n",
    "                if i > j:\n",
    "                    ij_ = np.abs(corr_frame.iat[i, j])\n",
    "                    if ij_ > CORR_THRESHOLD:\n",
    "                        out.write(str(i) + ',' + str(j) + ',' + str(ij_) +\n",
    "                                  '\\n')\n",
    "\n",
    "    return OUT_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAIN ROUTINE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of iterations need to be adjusted in accorance to the number of columns in transposed csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2gdf():\n",
    "    \n",
    "    \"\"\" Encodes categorical variables, calculates Pearson correlations,\n",
    "        and calls wite_gdf. \"\"\"\n",
    "\n",
    "    # read csv and keep inputs in X list\n",
    "    frame = pd.read_csv(IN_FILE)\n",
    "    rename_dict = {}\n",
    "\n",
    "    # Step 2: Iterate over the column names\n",
    "    for col in frame.columns:\n",
    "    # Iterate from 1 to 358 (No.of columns in Tranposed Embeddings .csv - 1) and check for prefix in column names\n",
    "        for i in range(1, 358):\n",
    "            prefix = f'DocID_{i}_Label_'\n",
    "            if col.startswith(prefix):\n",
    "                # Remove the prefix and add the new column name to the rename_dict\n",
    "                new_col_name = col.replace(prefix, '')\n",
    "                rename_dict[col] = new_col_name\n",
    "                break\n",
    "\n",
    "    # Step 3: Rename the columns using the rename_dict\n",
    "    frame = frame.rename(columns=rename_dict)\n",
    "    frame = frame[X_2]\n",
    "    # print(\"Updated column names:\", frame.columns.tolist())\n",
    "    \n",
    "    # collect names of variables\n",
    "    # to attempt to encode\n",
    "    try_name_list = [name for name, type_ in frame[X_2].dtypes.items()\n",
    "                     if type_ == 'object']\n",
    "\n",
    "    print('Encoding categorical columns ...')\n",
    "    \n",
    "    # handle unary \n",
    "    # don't encode unary categorical columns\n",
    "    unary_list = [name for name in try_name_list if\n",
    "                  len(frame[name].unique()) == 1]  \n",
    "    \n",
    "    if len(unary_list) > 0:\n",
    "        frame = frame.drop(unary_list, axis=1)\n",
    "        try_name_list = list(set(try_name_list) - set(unary_list))\n",
    "    \n",
    "    # encode binary\n",
    "    # don't create perfectly, negatively correlated encoded columns\n",
    "    binary_list = [name for name in try_name_list if\n",
    "                   len(frame[name].unique()) == 2] \n",
    "    \n",
    "    if len(binary_list) > 0:\n",
    "        dummies = pd.get_dummies(frame[binary_list], dummy_na=True,\n",
    "                                 drop_first=True)\n",
    "        frame = frame.drop(binary_list, axis=1)\n",
    "        frame = pd.concat([frame, dummies], axis=1) \n",
    "        try_name_list = list(set(try_name_list) - set(binary_list))\n",
    "    \n",
    "    # encode nominal\n",
    "    nominal_list = [name for name in try_name_list if\n",
    "                    len(frame[name].unique()) <=\n",
    "                    NUM_LEVELS_THRESHOLD and \n",
    "                    len(frame[name].unique()) > 2]\n",
    "\n",
    "    if len(nominal_list) > 0:\n",
    "        dummies = pd.get_dummies(frame[nominal_list], dummy_na=True)\n",
    "        frame = frame.drop(nominal_list, axis=1)\n",
    "        frame = pd.concat([frame, dummies], axis=1)\n",
    "    \n",
    "    print('Done.')\n",
    "\n",
    "    # calculate Pearson correlations\n",
    "    print('Calculating Pearson correlations ...')\n",
    "    corr_frame = frame.corr()\n",
    "    print('Done.')\n",
    "\n",
    "    # write gdf\n",
    "    print('Writing GDF file to %s ...' % write_gdf(corr_frame))\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the Main Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical columns ...\n",
      "Done.\n",
      "Calculating Pearson correlations ...\n",
      "Done.\n",
      "Writing GDF file to /Users/arnabraychaudhari/Documents/6317/Project_LLM_and_RAG_2024_GWU/Farm_Bill_train.gdf ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "csv2gdf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
